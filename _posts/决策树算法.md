---
title: 决策树算法

date: {{date}}
categories:
- 机器学习
tags:
- 机器学习
- 算法

---

# 1. 决策树（也叫判定树）含义
决策树是一个类似于流程图的树结构：其中，每个内部结点表示在一个属性上的测试，每个分支代表一个属性输出，而每个树叶结点代表类或类分布。树的最顶层是根结点。
![](https://i.loli.net/2019/08/20/UldXhCG36WiB89A.png)

# 2. 决策树示例
![](https://i.loli.net/2019/08/20/fbw8IPKJiU7h3lN.png)
![](https://i.loli.net/2019/08/20/vrClp7nNOWMK2bR.png)
![](https://pic2.zhimg.com/80/v2-dbb2bb70e13a445cab2fb55fbbbde8f5_hd.jpg)
# 2. 构建一个决策树基本算法
## 2.1 “熵”概念
[信息熵-维基百科](https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA))
[信息熵-百度百科](https://baike.baidu.com/item/%E7%86%B5/19190273)
**信息量的度量就等于不确定性的多少**, 当我们需要大量信息来确定一个事情，说明这件事的不确定性很大，我们才需要大量信息来确定，这时它的熵就很大（变量的不确定性越大，熵也就越大）。

## 2.2 决策树归纳算法（ID3）
- 选择属性判断结点（怎么选择根节点和其它节点）
- 信息获取量：Gain(A) = Info(D) - Info_A(D), 通过 A 来作为节点分类获取了多少信息。
![](https://i.loli.net/2019/08/20/vrClp7nNOWMK2bR.png)
![](https://i.loli.net/2019/08/24/DH4PAIgVBeKodWX.png)
![](https://i.loli.net/2019/08/24/8cqdG5hYmnOQD9k.png)

## 2.3 其它算法
- C4.5
- CART

**共同点：** 都是贪心算法，自顶而下
**区别：** 属性选择度量方法不同, C4.5(gain ratio)，CART(gain index)，ID3(information Gain)
## 2.4 树剪枝叶(避免overfitting，树深度过大，分类过细，测试集表现不好)
- 先剪枝（模型建立到一定程度就可以）
- 后剪枝（模型建立完进行剪枝）

# 3. 优缺点
**优点：**
- 直观，便于理解，小规模数据集有效

**缺点：**
- 处理连续变量不好（连续变量需要离散化）
- 类别较多时，错误增加的比较快
- 可规模性一般（适合小规模数据，大规模信息熵复杂度较高）


---
***参考：
[彭亮-麦子学院](https://www.bilibili.com/video/av16959124?from=search&seid=15885977379504396893)
[知乎](https://zhuanlan.zhihu.com/p/26703300)***
